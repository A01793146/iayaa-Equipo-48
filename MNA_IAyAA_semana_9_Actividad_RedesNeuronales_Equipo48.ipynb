{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A01793146/iayaa-Equipo-48/blob/main/MNA_IAyAA_semana_9_Actividad_RedesNeuronales_Equipo48.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFj0sSM06dYa"
      },
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "## **Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "### Tecnológico de Monterrey\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Adtividad de la Semana 7**\n",
        "### **Red Neuronal Artificial - Perceptrón Multicapa : Multilayer Perceptrón (MLP)**\n",
        "### Equipo 48"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgrvy0RGB9XI"
      },
      "source": [
        "**Nombres y matrículas de los integrantes del equipo:**\n",
        "\n",
        "* Axel Alejandro Tlatoa Villavicencio - A01363351\n",
        "* Christopher Valdéz Cantú - A01793549\n",
        "* Ernesto Nicanor Santillán Guerrero - A01793675\n",
        "* Alejandro Jesús Vázquez Navarro - A01793146  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrJ2ahMODVj1"
      },
      "source": [
        "En cada sección deberás incluir todas las líneas de código necesarias para responder a cada uno de los ejercicios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exXsscs-Dh-2"
      },
      "outputs": [],
      "source": [
        "# Incluye aquí todos módulos, librerías y paquetes que requieras.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn \n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Toda la navaja suiza para machine learning\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Modelos\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "\n",
        "# Para validación cruzada\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "#Para probar las métricas\n",
        "from sklearn.metrics import classification_report, make_scorer\n",
        "from sklearn import metrics \n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score\n",
        "\n",
        "\n",
        "# Para tabulación\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Para las curvas de aprendizaje\n",
        "from sklearn.model_selection import learning_curve, validation_curve\n",
        "\n",
        "# Para el Scaling\n",
        "from sklearn.preprocessing import StandardScaler   \n",
        "\n",
        "# Para el fine tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Para graficar\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "# Para transformación\n",
        "from sklearn.preprocessing import power_transform\n",
        "\n",
        "# Eliminar las warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X25brD-gQdZM"
      },
      "source": [
        "# **Ejercicio-1.** \n",
        "\n",
        "\n",
        "1- En esta tarea considera únicamente la siguiente variable de salida que se concluye que es una de las \n",
        "mejores en el artículo antes citado: ‘Lifetime People who have liked a Page and engaged with a \n",
        "post'. \n",
        "\n",
        "Renombra dicha variable como “LPE” . Como variables de entrada selecciona las 7 variables \n",
        "que indican los autores en la Tabla 3 del artículo citado. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nU2GuWYCy6C"
      },
      "outputs": [],
      "source": [
        "#Lectura de los datos\n",
        "dfMain = pd.read_csv(\"dataset_Facebook.csv\", sep=\";\", index_col=False)\n",
        "\n",
        "#Renombrar variable solicitada\n",
        "dfMain.rename(columns ={'Lifetime People who have liked your Page and engaged with your post':'LPE'}, inplace=True)\n",
        "\n",
        "dfMain = dfMain[[\"LPE\", \"Category\", \"Page total likes\", \"Post Month\", \"Post Hour\", \"Post Weekday\", \"Paid\"]]\n",
        "\n",
        "print(f'Total de registros en dfMain: {len(dfMain)}')\n",
        "#Selección de las variables predictoras de acuerdo al artículo\n",
        "X = dfMain.drop('LPE', axis=1)\n",
        "\n",
        "print(f'Columnas de  {X.columns}')\n",
        "\n",
        "Y = dfMain[\"LPE\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZhr2hkECzVv"
      },
      "source": [
        "# **Ejercicio-2.**\n",
        "\n",
        "2- Realiza una partición de los datos con 100 datos de Prueba y el resto para entrenamiento y \n",
        "validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGfAoOPkC1PP"
      },
      "outputs": [],
      "source": [
        "# Utilizamos train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.80, random_state=10)\n",
        "\n",
        "print(f'Tamaño de X prueba: {X_test.shape}')\n",
        "print(f'Tamaño de Y prueba: {y_test.shape}')\n",
        " \n",
        "print(f'Tamaño de X entrenamiento: {X_train.shape}')\n",
        "print(f'Tamaño de Y entrenamiento: {y_train.shape}')\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCunuooTC2W3"
      },
      "source": [
        "# **Ejercicio-3.**\n",
        "\n",
        "3- Definirás tus propias funciones de errores para este problema de regresión. \n",
        "Los errores que utilizarás son la **raíz cuadrada del error cuadrático medio RMSE**, **el error absoluto medio MAE** y el **error porcentual absoluto medio MAPE.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXlcSWA-C4Dj"
      },
      "outputs": [],
      "source": [
        "# Definición de funciones de errores:\n",
        "\n",
        "def mi_RMSE(y_val_, yhatVal):\n",
        "    mse =  np.square(np.subtract(y_val_, yhatVal)).mean()\n",
        "    rmse = np.sqrt(mse)\n",
        "    \n",
        "    return rmse\n",
        "\n",
        "\n",
        "# Incluye aquí las líneas de código que definan a la función: mi_MAE:\n",
        "def mi_MAE(y_val_, yhatVal):\n",
        "\n",
        "    y_val_ = np.array(y_val_)\n",
        "    yhatVal = np.array(yhatVal)\n",
        "\n",
        "    return np.mean(np.abs(y_val_ - yhatVal))\n",
        "\n",
        "\n",
        "# Incluye aquí las líneas de código que definan a la función: mi_MAPE:\n",
        "def mi_MAPE(actual, pred): \n",
        "    actual, pred = np.array(actual), np.array(pred)\n",
        "    \n",
        "    return np.mean(np.abs((actual - pred) / actual)) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKI80-YdC4HN"
      },
      "outputs": [],
      "source": [
        "dfMain.isna().sum().sum()\n",
        "dfMain.isnull()\n",
        "# Tenemos un valor nulo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chqk9jIDC5Pq"
      },
      "source": [
        "# **Ejercicio-4.**\n",
        "\n",
        "4- En la página de la UCI, así como en el artículo de los autores previamente citado encuentras \n",
        "información en relación al significado de cada variable. \n",
        "\n",
        "* Haz una análisis de tus datos y lleva a cabo las transformaciones que consideres adecuadas tanto en los datos de entrada, como en las de salida. \n",
        "\n",
        "* Utiliza un Pipeline para evitar el filtrado de información. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBVSFwK4C6g9"
      },
      "outputs": [],
      "source": [
        "# Analicemos si existen datos perdidos\n",
        "\n",
        "\n",
        "\n",
        "# Lo primero que debemos hacer es identificar los tipos de variable, posteriormente identificar dónde hay valors NaN, \n",
        "# calcular distribuciones y posteriormente determinar el mejor criterio para imputar datos faltantes\n",
        "# Identificación de tipo de variables\n",
        "\n",
        "#Variables numéricas\n",
        "#Removí 'Category' y 'Paid' porque son variables nominales\n",
        "\n",
        "colCategoricas = ['Category', 'Paid']\n",
        "colNumericas =['Page total likes', 'Post Month', 'Post Hour','Post Weekday']\n",
        "\n",
        "#Todas son variables numéricas\n",
        "#Veamos cómo están sus distribuciones y sus escalas\n",
        "\n",
        "sns.set(rc={'figure.figsize':(17,18)})\n",
        "fig, axes = plt.subplots(4, 5)    \n",
        "  \n",
        "for k in range(0,4):       \n",
        " \n",
        "  \n",
        "    # Datos originales ---------------------------------------------------------\n",
        "    plt.subplot(5,4,k+1) \n",
        "\n",
        "    Transf0 = dfMain[colNumericas[k]]         \n",
        "    sns.histplot(data=Transf0, bins=20)                    \n",
        "\n",
        "    plt.xlabel(colNumericas[k])\n",
        "    if k==0:\n",
        "        plt.ylabel('Originales')\n",
        "    \n",
        "\n",
        "\n",
        "    # Datos transformados con raíz cuadrada ------------------------------------\n",
        "    plt.subplot(5,4,k+5)    \n",
        "\n",
        "    Transf1 = np.sqrt(dfMain[colNumericas[k]]) \n",
        "    sns.histplot(data=Transf1, bins=20)                     \n",
        "\n",
        "\n",
        "    plt.xlabel(colNumericas[k])\n",
        "    if k==0:\n",
        "        plt.ylabel('Raíz Cuadrada')\n",
        "    \n",
        "\n",
        "    \n",
        "    # Datos transformados con logaritmo natural --------------------------------\n",
        "    plt.subplot(5,4,k+9)     \n",
        "\n",
        "    Transf2 = np.log(dfMain[colNumericas[k]])   \n",
        "    sns.histplot(data=Transf2, bins=20)                     \n",
        "\n",
        "\n",
        "    plt.xlabel(colNumericas[k])\n",
        "    if k==0:\n",
        "        plt.ylabel('Logaritmo')\n",
        "    \n",
        "\n",
        "\n",
        "    # Datos transformados con la potencia de 2 ---------------------------------\n",
        "    plt.subplot(5,4,k+13)\n",
        "\n",
        "    Transf3 = np.power(dfMain[colNumericas[k]], 2)\n",
        "    sns.histplot(data=Transf3, bins=20)                        \n",
        "\n",
        "\n",
        "    plt.xlabel(colNumericas[k])\n",
        "    if k==0:\n",
        "        plt.ylabel('Potencia 2')\n",
        "    \n",
        "    # Datos transformados con Box-Cox ------------------------------------------\n",
        "    plt.subplot(5,4,k+17)\n",
        "\n",
        "    Transf4 = power_transform(np.array(dfMain[colNumericas[k]]).reshape(-1, 1), method=\"box-cox\")  \n",
        "    sns.histplot(Transf4, bins=20)                               \n",
        "\n",
        "\n",
        "    plt.xlabel(colNumericas[k])\n",
        "    if k==0:\n",
        "        plt.ylabel('Box-Cox')\n",
        "\n",
        "    \n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtWYAuf-TyC8"
      },
      "outputs": [],
      "source": [
        "# De acuerdo a este análisis, será conveniente aplicar transformaciones de MinMaxScaler y SimpleImputer para \n",
        "# las variables con NaN\n",
        "\n",
        "num_pipeline = Pipeline(steps = [('impMediana', SimpleImputer(strategy='median')),\n",
        "                                 ('escalaNum', MinMaxScaler(feature_range=(1,2)))])   \n",
        "\n",
        "cat_pipeline = Pipeline(steps = [('impMediana', SimpleImputer(strategy='median'))])  \n",
        "\n",
        "num_pipeline_nombres = colNumericas\n",
        "cat_pipeline_nombres = colCategoricas\n",
        "\n",
        "# Transformación One-Hot encoding a variables de entrada de tipo categórico:\n",
        "# catOHE_pipeline = Pipeline(steps = [('OneHotE', OneHotEncoder(drop='first', handle_unknown='ignore'))])\n",
        "# catOHE_pipeline_nombres = colCategoricas\n",
        "\n",
        "\n",
        "# Creación de Pipeline:\n",
        "# columnasTransformer = ColumnTransformer(transformers = [('numpipe', num_pipeline, num_pipeline_nombres),\n",
        "#                                                        ('catohe', catOHE_pipeline, catOHE_pipeline_nombres)],\n",
        "#                                                        remainder='passthrough')\n",
        "\n",
        "\n",
        "# Creación de Pipeline:\n",
        "columnasTransformer = ColumnTransformer(transformers = [\n",
        "                                    ('numpipe', num_pipeline, num_pipeline_nombres),\n",
        "                                    ('catpipe', cat_pipeline, cat_pipeline_nombres)\n",
        "                                                       ],\n",
        "                               remainder='passthrough')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv7KFq-mC7PS"
      },
      "source": [
        "# **Ejercicio-5.**\n",
        "\n",
        "5- Utiliza la función Dummy para modelos de regresión de scikit-learn con el conjunto que tienes de \n",
        "datos de entrenamiento y validación. \n",
        "\n",
        "- Para ello particiónalos en 100 para validación y 300 para entrenamiento. Encuentra los errores RMSE, MAE y MAPE para los conjuntos de entrenamiento y validación. \n",
        "\n",
        "- Estos serán tus errores máximos que deberás tomar como referencia en el resto de la \n",
        "actividad. \n",
        "\n",
        "- Consulta su documentación correspondiente: \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaDj3kawC9B6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tQxQROVC9Us"
      },
      "outputs": [],
      "source": [
        "#Particionar los datos de entrenamiento en 100 para validación y 300 para entrenamiento\n",
        "X__train, X__val, y__train, y__val = train_test_split(X_train, y_train, test_size=100/400, random_state=10)\n",
        "\n",
        "#Verificamos el tamaño\n",
        "\n",
        "print(f'Tamaño de las X de Validación X__val {X__val.shape}')\n",
        "print(f'Tamaño de las Y de Validación y__val {y__val.shape}')\n",
        "print('---' * 20)\n",
        "print(f'Tamaño de las X de Training X__train {X__train.shape}')\n",
        "print(f'Tamaño de las Y de Training Y__train {X__train.shape}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--5P3myqTyC-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWt7qktnTyC-"
      },
      "outputs": [],
      "source": [
        "\n",
        "modelo_dummy= DummyRegressor().fit(X__train, y__train)\n",
        "\n",
        "y_pred = modelo_dummy.predict(X__val)\n",
        "y_pred_train = modelo_dummy.predict(X__train)\n",
        "\n",
        "print(\"Mi baseline Validación:\")\n",
        "print(\"-\" * 50)\n",
        "print('Mi RMSE:', mi_RMSE(y__val, y_pred))\n",
        "print('Mi MAE:', mi_MAE(y__val, y_pred))\n",
        "print('Mi MAPE:', mi_MAPE(y__val, y_pred))\n",
        "\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Mi baseline Entrenamiento:\")\n",
        "print(\"-\" * 50)\n",
        "print('Mi RMSE:', mi_RMSE(y__train, y_pred_train))\n",
        "print('Mi MAE:', mi_MAE(y__train, y_pred_train))\n",
        "print('Mi MAPE:', mi_MAPE(y__train, y_pred_train))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2S7LI0NC9wE"
      },
      "source": [
        "# **Ejercicio-6.**\n",
        "\n",
        "6- Usando los modelos de regresión lineal múltiple, el bosque aleatorio y el perceptrón multicapa con \n",
        "sus valores predeterminados, lleva a cabo su entrenamiento con repeticiones de validación cruzada \n",
        "(RepeatedKFold) y desplegando los errores RMSE, MAE y MAPE. \n",
        "\n",
        "Recuerda evitar el filtrado de información usando los datos que obtuviste en el ejercicio 2. Incluye las conclusiones sobre el mejor modelo encontrado en esta primera aproximación. En particular ¿hay alguno sobreentrenado o \n",
        "subentrenado? \n",
        "\n",
        "**NOTA: Recuerda que puedes aumentar en dado caso el número máximo de iteraciones para que todos los modelos converjan.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6uBleJUC_AU"
      },
      "outputs": [],
      "source": [
        "def get_modelos():\n",
        "    \n",
        "    modelos, nombres = list(), list()\n",
        "\n",
        "    modelos.append(LinearRegression())\n",
        "    nombres.append('LinearRegression')\n",
        "    \n",
        "    modelos.append(RandomForestRegressor())\n",
        "    nombres.append('RandomForest')\n",
        "    \n",
        "    modelos.append(MLPRegressor(solver='lbfgs', \n",
        "                              alpha=1e-5,\n",
        "                              hidden_layer_sizes=(6,100), \n",
        "                              random_state=1))\n",
        "                       \n",
        "                  \n",
        "    nombres.append('Perceptrón Multicapa')\n",
        "    \n",
        "    \n",
        "    \n",
        "    return modelos, nombres\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0P_AcyjC_Dh"
      },
      "outputs": [],
      "source": [
        "modelosOU, nombres = get_modelos()       \n",
        "resultados = list()\n",
        "resultadosTodos = list()\n",
        "\n",
        "for i in range(len(modelosOU)):\n",
        "\n",
        "    cv = RepeatedKFold(n_splits=5, n_repeats=20, random_state=123)\n",
        "    pipe = Pipeline([('preprocessing', columnasTransformer),\n",
        "                     ('modelo', modelosOU[i])])\n",
        "\n",
        "    scoring = {'RSME': make_scorer(mi_RMSE), 'MAE': make_scorer(mi_MAE), 'MAPE': make_scorer(mi_MAPE)}\n",
        "\n",
        "    cv_scores = cross_validate(\n",
        "                    estimator = pipe,\n",
        "                    X         = X,\n",
        "                    y         = Y,\n",
        "                    scoring   = scoring,\n",
        "                    cv        = cv,\n",
        "                    return_train_score = True\n",
        "                 )\n",
        "\n",
        "    resultadosTodos.append(cv_scores)\n",
        "    \n",
        "    train_mae  = round(cv_scores['train_MAE'].mean(),5)\n",
        "    train_rsme = round(cv_scores['train_RSME'].mean(), 5)\n",
        "    train_mape = round(cv_scores['train_MAPE'].mean(), 5)\n",
        "\n",
        "    test_mae  = round(cv_scores['test_MAE'].mean(),5)\n",
        "    test_rsme = round(cv_scores['test_RSME'].mean(), 5)\n",
        "    test_mape = round(cv_scores['test_MAPE'].mean(), 5)\n",
        "    resultados.append([train_mae, test_mae, train_rsme, test_rsme, train_mape, test_mape])\n",
        "# Se convierte el diccionario a dataframe para facilitar la visualización\n",
        "\n",
        "\n",
        "dfScores = pd.DataFrame(resultados, columns = ['Train MAE', 'Test MAE', 'Train RSME', 'Test RSME', 'Train MAPE', 'Test MAPE'], \n",
        "             index=nombres).sort_values('Train MAE', ascending=False)\n",
        "\n",
        "dfScores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De acuerdo a estos resultados, podemos observar:\n",
        "- La regresión linear tiene baja varianza (Train MAPE (137.69) - Test MAPE (140.26) pero alto bias (137.69 en el entrenamiento; este valor está muy alejado de 0 (cero)), esto a todas luces es un modelo **subentrenado** lo cual es lógico debido a que no tien\n",
        "e afinamiento de hiperparámetros.\n",
        "\n",
        "- El modelo de perceptrón multicapa tiene baja varianza (Train MAPE (130.15) - Test MAPE (134.29) pero alto bias (120.15 en el entrenamiento; este valor está muy alejado de 0 (cero)), esto a todas luces es un modelo **subentrenado** lo cual es lógico debido a que no tiene afinamiento de hiperparámetros.\n",
        "\n",
        "- El modelo de Random Forest tiene alta varianza (Train 54.2) - Test MAPE (140.4) y un relativo bajo sesgo (54.22 en el entrenamiento; este valor no está tan alejado de cero), esto puede interpretarse como un modelo ** sobreentrenado **, es natural porque no tiene afinación de hiperparámetros."
      ],
      "metadata": {
        "id": "ptyTYytDc45e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZRPK8pGTyDA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNGx4TQ8CFI"
      },
      "source": [
        "#**Ejercicio-7.**\n",
        "\n",
        "7- Obtener los diagramas de caja y bigote para los errores MAPE de los conjuntos de validación \n",
        "obtenidos. \n",
        "\n",
        "En particular compara estos primeros resultados de MAPE con el mejor resultado que \n",
        "encuentran los autores del artículo citado al inicio. Incluye tus conclusiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewvwUcJX78y1"
      },
      "outputs": [],
      "source": [
        "sns.set(rc={'figure.figsize':(8,4)})\n",
        "\n",
        "\n",
        "\n",
        "MAPE = list()\n",
        "for i in range(len(resultadosTodos)):\n",
        "  rr = resultadosTodos[i]['test_MAPE']\n",
        "  MAPE.append(rr)\n",
        "\n",
        "plt.boxplot(MAPE, labels=nombres, showmeans=True)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1aW0dQX8BLL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando estos resultados contra los obtenidos por los autores del 2016 de Moro, Rita & Vala (https://www.semanticscholar.org/paper/Predicting-social-media-performance-metrics-and-of-Moro-Rita/dec55692590820754b53c916e29bb2b42c0e5104) los modelos desempeñan pobremente. \n",
        "\n",
        "La métrica de comparación es \"Lifetime people who have liked you page and engaged with your post\" y obtuvo en el artículo un MAPE de 26.5; nuestro mejor modelo (hasta este momento es el Random Forest) con un MAPE de 54.27 promedio. Esto indica que debemos hacer ajustes aún a nuestros modelos con un gridsearch. Habría sido sorprendente que en esta primera iteración obtuviéramos métricas de performance alto.\n"
      ],
      "metadata": {
        "id": "C7sGZiuvD7rf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzQn5NR78GFg"
      },
      "source": [
        "#**Ejercicio-8.**\n",
        "\n",
        "- Usando una búsqueda de malla con validación cruzada (GridSearchCV), busca los mejores \n",
        "hiperparámetros para el modelo MLP. Al menos deberás realizar la búsqueda en los \n",
        "hiperparámetros “hidden_layer_sizes”, “alpha” y “learning_rate_init”. Además aplica la validación \n",
        "cruzada con repeticiones (RepeatedKFold). Muestra los mejores hiperparámetros encontrados. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBKcp0278IQV"
      },
      "outputs": [],
      "source": [
        "modelo = MLPRegressor(hidden_layer_sizes=(6,100), \n",
        "                      solver='adam',               \n",
        "                      random_state=1)\n",
        "\n",
        "        \n",
        "dicc_grid = {\"hidden_layer_sizes\": [1,50], \"alpha\": [0.00005,0.0005], \"learning_rate_init\": np.arange(0.01,1.01,0.1) }\n",
        "\n",
        "scoring = {'MAPE': make_scorer(mi_MAPE)}\n",
        "\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=20, random_state=123)\n",
        "\n",
        "grid = GridSearchCV(estimator=modelo, \n",
        "                    param_grid=dicc_grid, \n",
        "                    cv=cv,    \n",
        "                    verbose=5,\n",
        "                    n_jobs=-1,\n",
        "                    scoring   = 'neg_mean_absolute_percentage_error'\n",
        "                    )\n",
        "\n",
        "# Transformamos los datos de entrada:\n",
        "Xx = columnasTransformer.fit_transform(X_train)\n",
        "\n",
        "grid.fit(Xx, np.ravel(y_train))\n",
        "\n",
        "print('Mejor valor de exactitud obtenido con la mejor combinación:', grid.best_score_)\n",
        "print('Mejor combinación de valores encontrados de los hiperparámetros:', grid.best_params_)\n",
        "print('Métrica utilizada:', grid.scoring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp8S0PFs8IMR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mASNrZWs8JTh"
      },
      "source": [
        "#**Ejercicio-9.**\n",
        "\n",
        "Con los mejores valores de los hiperparámetros encontrados realiza un análisis de la importancia de \n",
        "los factores. Muestra un diagrama de barras de los resultados e incluye tus conclusiones. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6HJP9hb8LCp"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr6oe1VF8K_A"
      },
      "outputs": [],
      "source": [
        "# Una vez inicializado y entrenada la MLP, veamos qué factores considera más importantes:\n",
        "\n",
        "modelo_MLP = MLPRegressor(\n",
        "                            alpha=5e-05,\n",
        "                            hidden_layer_sizes= 1,\n",
        "                            learning_rate_init=0.01)  \n",
        "\n",
        "# Transformamos los datos de entrada:\n",
        "Xx = columnasTransformer.fit_transform(X_train)\n",
        "\n",
        "modelo_MLP.fit(Xx,  np.ravel(y_train))\n",
        "\n",
        "importance = permutation_importance(modelo_MLP, Xx, np.ravel(y_train), n_repeats=10)\n",
        "\n",
        "# visualicemos la importancia de cada métrica, de las cuales sabemos\n",
        "# cuáles son las más importantes, de acuerdo a como se definieron al inicio:\n",
        "\n",
        "for i,v in enumerate(importance['importances_mean']):\n",
        "\tprint('Feature: %0d, Score: %.9f' % (i,v))\n",
        " \n",
        "plt.bar([x for x in range(len(importance['importances_mean']))], importance['importances_mean'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUIcDshs8MzG"
      },
      "source": [
        "#**Ejercicio-10.**\n",
        "\n",
        "Repite el ejercicio 8 y 9 para el modelo de **bosque aleatorio** para buscar sus mejores \n",
        "hiperparámetros (realiza la búsqueda con aquellos hiperparámetros que consideres más \n",
        "adecuados) y usando el conjunto de Prueba. Y realiza igualmente el análisis de importancia de \n",
        "factores con este modelo con un diagrama de barras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lKNJNIt8N88"
      },
      "outputs": [],
      "source": [
        "# Bosque Aleatorio\n",
        "modelo = RandomForestRegressor()\n",
        "        \n",
        "dicc_grid = {\n",
        "    'n_estimators': [100, 150, 200, 250, 300],\n",
        "    'max_depth': [1,2,3,4],\n",
        "}\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=8)\n",
        "\n",
        "grid = GridSearchCV(estimator=modelo, \n",
        "                    param_grid=dicc_grid, \n",
        "                    cv=cv, \n",
        "                    verbose=5,\n",
        "                    n_jobs=-1,\n",
        "                    scoring   = 'neg_mean_absolute_percentage_error'\n",
        "                    )\n",
        "\n",
        "# Transformamos los datos de entrada:\n",
        "Xx = columnasTransformer.fit_transform(X_test)\n",
        "\n",
        "grid.fit(Xx, np.ravel(y_test))\n",
        "\n",
        "print('Mejor valor de exactitud obtenido con la mejor combinación:', grid.best_score_)\n",
        "print('Mejor combinación de valores encontrados de los hiperparámetros:', grid.best_params_)\n",
        "print('Métrica utilizada:', grid.scoring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Inkq5YQe8PED"
      },
      "outputs": [],
      "source": [
        "# Importancias de las características del RandomForestRegressor\n",
        "\n",
        "modelo_RF = RandomForestRegressor(\n",
        "                           max_depth=2,\n",
        "                           n_estimators = 150\n",
        "                           )  \n",
        "\n",
        "# Transformamos los datos de entrada:\n",
        "Xx = columnasTransformer.fit_transform(X_test)\n",
        "\n",
        "modelo_RF.fit(Xx,  np.ravel(y_test))\n",
        "\n",
        "importance = permutation_importance(modelo_RF, Xx, np.ravel(y_test), n_repeats=10)\n",
        "\n",
        "# visualicemos la importancia de cada métrica, de las cuales sabemos\n",
        "# cuáles son las más importantes, de acuerdo a como se definieron al inicio:\n",
        "\n",
        "for i,v in enumerate(importance['importances_mean']):\n",
        "\tprint('Feature: %0d, Score: %.9f' % (i,v))\n",
        " \n",
        "plt.bar([x for x in range(len(importance['importances_mean']))], importance['importances_mean'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LJl6oql8Pc8"
      },
      "source": [
        "#**Ejercicio-11.**\n",
        "\n",
        "Repite el ejercicio 8 y 9 para el modelo de **regresión lineal múltiple** para buscar sus mejores \n",
        "hiperparámetros (realiza la búsqueda con aquellos hiperparámetros que consideres más \n",
        "adecuados) y usando el conjunto de Prueba. Y realiza igualmente el análisis de importancia de \n",
        "factores con este modelo con un diagrama de barras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YiSnt9t8RfN"
      },
      "outputs": [],
      "source": [
        "#Usando Ridge\n",
        "\n",
        "# Regresión Lineal Múltiple\n",
        "modelo = LinearRegression()\n",
        "\n",
        "dicc_grid={'fit_intercept':[True, False], 'normalize': [True, False], 'copy_X':[True, False]}\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=8)\n",
        "\n",
        "grid = GridSearchCV(estimator=modelo, \n",
        "                    param_grid=dicc_grid, \n",
        "                    cv=cv, \n",
        "                    verbose=5,\n",
        "                    n_jobs=-1,\n",
        "                    scoring   = 'neg_mean_absolute_percentage_error'\n",
        "                    )\n",
        "\n",
        "# Transformamos los datos de entrada:\n",
        "Xx = columnasTransformer.fit_transform(X_test)\n",
        "\n",
        "grid.fit(Xx, np.ravel(y_test))\n",
        "\n",
        "print('Mejor valor de exactitud obtenido con la mejor combinación:', grid.best_score_)\n",
        "print('Mejor combinación de valores encontrados de los hiperparámetros:', grid.best_params_)\n",
        "print('Métrica utilizada:', grid.scoring)\n",
        "print(\"---\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iRA78ZC8Rbm"
      },
      "outputs": [],
      "source": [
        "# Importancia de las características de Regresión Lineal Múltiple\n",
        "\n",
        "modelo_RL = LinearRegression(\n",
        "                           copy_X=True,\n",
        "                           fit_intercept = True,\n",
        "                           normalize = True\n",
        "                           )  \n",
        "\n",
        "# Transformamos los datos de entrada:\n",
        "Xx = columnasTransformer.fit_transform(X_test)\n",
        "\n",
        "modelo_RL.fit(Xx,  np.ravel(y_test))\n",
        "\n",
        "importance = permutation_importance(modelo_RL, Xx, np.ravel(y_test), n_repeats=10)\n",
        "\n",
        "# visualicemos la importancia de cada métrica, de las cuales sabemos\n",
        "# cuáles son las más importantes, de acuerdo a como se definieron al inicio:\n",
        "\n",
        "for i,v in enumerate(importance['importances_mean']):\n",
        "\tprint('Feature: %0d, Score: %.9f' % (i,v))\n",
        " \n",
        "plt.bar([x for x in range(len(importance['importances_mean']))], importance['importances_mean'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKW72uyk8Sbc"
      },
      "source": [
        "#**Ejercicio-12.**\n",
        "\n",
        "- Compara tus resultados con los obtenidos por los autores del artículo de Moro-Rita-Vala con \n",
        "respecto a MAPE. Incluye tus conclusiones finales de la actividad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwpz77W38Uq0"
      },
      "outputs": [],
      "source": [
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v8HL02W8UmW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ql_r2G-DB_m"
      },
      "source": [
        "###**Fin de la Actividad de la semana 7.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "X25brD-gQdZM",
        "NCunuooTC2W3",
        "Rv7KFq-mC7PS",
        "7ql_r2G-DB_m"
      ],
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}